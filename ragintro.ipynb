{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace295fa-4c6f-419c-9d33-85202a1ad344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  This one is for Elastic search the previous code is for Min Search\n",
    "from elasticsearch.helpers import bulk\n",
    "import json\n",
    "import glob\n",
    "from elasticsearch import Elasticsearch\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    hosts=[{\n",
    "        'host': 'localhost',\n",
    "        'port': 9200,\n",
    "        'scheme': 'http'  # Specify the scheme\n",
    "    }]\n",
    ")\n",
    "\n",
    "\n",
    "# Index name\n",
    "index_name = 'nbe_directives'\n",
    "\n",
    "# Define the index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"page_number\": {\"type\": \"text\"},\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"source_file\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Delete the index if it exists\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "# Create the index\n",
    "es.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "# Initialize an empty list to hold the documents\n",
    "documents = []\n",
    "\n",
    "# Specify the correct path to the directory containing the JSON files\n",
    "json_files_path = 'C:/Users/EstifanosT/AwashRagSystem/ConvertedToJson/*.json'\n",
    "\n",
    "# Get the list of JSON files in the directory\n",
    "json_files = glob.glob(json_files_path)\n",
    "\n",
    "# Iterate over each JSON file in the directory\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'rt', encoding='utf-8') as f_in:\n",
    "            doc_raw = json.load(f_in)\n",
    "            # Check if 'pages' key exists in the JSON\n",
    "            if 'pages' not in doc_raw:\n",
    "                continue\n",
    "            # Iterate over each page dictionary in the 'pages' list\n",
    "            for page_dict in doc_raw['pages']:\n",
    "                content = page_dict.get('content', '').strip()\n",
    "                if content:  # Ensure the content is not empty\n",
    "                    # Create a new dictionary to store the content and page number\n",
    "                    doc = {\n",
    "                        '_index': index_name,\n",
    "                        '_source': {\n",
    "                            'page_number': page_dict.get('page_number', 'Unknown'),\n",
    "                            'content': content,\n",
    "                            'source_file': json_file\n",
    "                        }\n",
    "                    }\n",
    "                    # Append the dictionary to the 'documents' list\n",
    "                    documents.append(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {json_file}: {e}\")\n",
    "\n",
    "if not documents:\n",
    "    raise ValueError(\"No valid documents found for indexing. Ensure the documents have content.\")\n",
    "\n",
    "# Bulk index the documents\n",
    "bulk(es, documents)\n",
    "\n",
    "def search(query):\n",
    "    # Search the Elasticsearch index\n",
    "    results = es.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"content\", \"source_file\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Extract the relevant information from the search results\n",
    "    hits = results['hits']['hits']\n",
    "    search_results = []\n",
    "    for hit in hits:\n",
    "        search_results.append(hit['_source'])\n",
    "\n",
    "    return search_results\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Provide a direct answer to the QUESTION based on the CONTEXT from the NBE directive.\n",
    "    Answer the QUESTION concisely and accurately using only the facts from the CONTEXT.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context += f\"source_file: {doc['source_file']}\\npage_number: {doc['page_number']}\\ncontent: {doc['content']}\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a295d0-f82f-4d0b-9117-8a15c843c5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('What does it mean Acceptable Foreign Currency?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85b66c9e-eee3-4cf2-b1b5-9d1c0e7ab403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, specifically from the sources:\\n\\n* source_file: C:/Users/EstifanosT/AwashRagSystem/ConvertedToJson\\\\FCP-01-2020.json\\n* page_number: 98\\n* content: ... WARNING: Fees other than those listed above may apply to your account. ...\\n\\nA concession refers to:\\n\\n\"... the lender(s) of the borrower, for economic or contractual reasons relating to the borrower\\'s financial difficulty, having granted to the borrower a concession(s) that the lender(s) would not otherwise consider...\"\\n\\nIn simpler terms, a concession is a favor or relaxation in credit terms that a lender grants to a borrower experiencing financial difficulties, which the lender would not normally do. This can include, for example, releasing collateral or accepting lower levels of collateralization, allowing the conversion of debt to equity, deferring recovery/collection actions for extended periods of time, or easing of covenants.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('what does it mean by Concession?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476d0f1-5de3-46bf-ba1b-c4747643aa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
